import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn. Linear_model import Linear Regression
from sklearn.metrics import mean squared error, r2 score

df = pd.read csv('kc house data.csv.zip")

print(df.head())

print(df.describe())

print(df.isnull().sum())

x = df[['bedrooms", 'bathrooms', 'sqft living', 'sqft lot', 'floors', 'waterfront", "view", "condition"]]
y = df['price']

x_train, x_test, y train, y test train test split(x, y, test size-0.2, random state-4)

model-Linearlegression()

model.fit(X_train, y_train)

y_pred model.predict(x_test)

Mse=mean squared_error(y_test, y pred)
r2=r2_score(y test, y_pred)

print("Mean Squared Error:", mse)
print("R-squared:", r2)

plt.scatter(y_test, y_pred)
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Actual prices vs. Predicted Prices")
plt.show()

residuals y_test - y pred
plt.scatter(y_test, residuals)
plt.axhline(y=0, color="red", linestyle="--")
plt.xlabel("Actual Prices")
plt.ylabel("Residuals")
plt.title("Residual Plot")
plt.show()

new_data=[[3 , 2, 1500, 4000, 1, 0, 0, 3]]
predicted_price model.predict(new_data)

print("Predicted Price:", predicted_price[0])
